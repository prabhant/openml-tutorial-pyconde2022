{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Flows and Runs\n",
    "\n",
    "How to train/run a model and how to upload the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# License: BSD 3-Clause\n",
    "\n",
    "import openml\n",
    "from sklearn import compose, ensemble, impute, neighbors, preprocessing, pipeline, tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train machine learning models\n",
    "\n",
    "Train a scikit-learn model on the data manually.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: We are using dataset 68 from the test server: https://test.openml.org/d/68\n",
    "dataset = openml.datasets.get_dataset(31)\n",
    "X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "    dataset_format=\"array\", target=dataset.default_target_attribute\n",
    ")\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also ask for meta-data to automatically preprocess the data.\n",
    "\n",
    "* e.g. categorical features -> do feature encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features: [True, True, False, True, False, False, True, True, True, True, True]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = openml.datasets.get_dataset(17)\n",
    "X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "    dataset_format=\"array\", target=dataset.default_target_attribute\n",
    ")\n",
    "print(f\"Categorical features: {categorical_indicator}\")\n",
    "transformer = compose.ColumnTransformer(\n",
    "    [(\"one_hot_encoder\", preprocessing.OneHotEncoder(categories=\"auto\"), categorical_indicator)]\n",
    ")\n",
    "X = transformer.fit_transform(X)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs: Easily explore models\n",
    "We can run (many) scikit-learn algorithms on (many) OpenML tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a task\n",
    "task = openml.tasks.get_task(31)\n",
    "\n",
    "# Build any classifier or pipeline\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Run the flow\n",
    "run = openml.runs.run_model_on_task(clf, task)\n",
    "\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Share the run on the OpenML server\n",
    "\n",
    "So far the run is only available locally. By calling the publish function,\n",
    "the run is sent to the OpenML server:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myrun = run.publish()\n",
    "# For this tutorial, our configuration publishes to the test server\n",
    "# as to not pollute the main server.\n",
    "print(f\"Uploaded to {myrun.openml_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now also inspect the flow object which was automatically created:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = openml.flows.get_flow(run.flow_id)\n",
    "print(flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It also works with pipelines\n",
    "\n",
    "When you need to handle 'dirty' data, build pipelines to model then automatically.\n",
    "To demonstrate this using the dataset `credit-a <https://test.openml.org/d/16>`_ via\n",
    "`task <https://test.openml.org/t/96>`_ as it contains both numerical and categorical\n",
    "variables and missing values in both.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = openml.tasks.get_task(96)\n",
    "\n",
    "# OpenML helper functions for sklearn can be plugged in directly for complicated pipelines\n",
    "from openml.extensions.sklearn import cat, cont\n",
    "\n",
    "pipe = pipeline.Pipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"Preprocessing\",\n",
    "            compose.ColumnTransformer(\n",
    "                [\n",
    "                    (\n",
    "                        \"categorical\",\n",
    "                        preprocessing.OneHotEncoder(sparse=False, handle_unknown=\"ignore\"),\n",
    "                        cat,  # returns the categorical feature indices\n",
    "                    ),\n",
    "                    (\n",
    "                        \"continuous\",\n",
    "                        impute.SimpleImputer(strategy=\"median\"),\n",
    "                        cont,\n",
    "                    ),  # returns the numeric feature indices\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        (\"Classifier\", ensemble.RandomForestClassifier(n_estimators=10)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "run = openml.runs.run_model_on_task(pipe, task, avoid_duplicate_runs=False)\n",
    "myrun = run.publish()\n",
    "print(f\"Uploaded to {myrun.openml_url}\")\n",
    "\n",
    "\n",
    "# The above pipeline works with the helper functions that internally deal with pandas DataFrame.\n",
    "# In the case, pandas is not available, or a NumPy based data processing is the requirement, the\n",
    "# above pipeline is presented below to work with NumPy.\n",
    "\n",
    "# Extracting the indices of the categorical columns\n",
    "features = task.get_dataset().features\n",
    "categorical_feature_indices = []\n",
    "numeric_feature_indices = []\n",
    "for i in range(len(features)):\n",
    "    if features[i].name == task.target_name:\n",
    "        continue\n",
    "    if features[i].data_type == \"nominal\":\n",
    "        categorical_feature_indices.append(i)\n",
    "    else:\n",
    "        numeric_feature_indices.append(i)\n",
    "\n",
    "pipe = pipeline.Pipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"Preprocessing\",\n",
    "            compose.ColumnTransformer(\n",
    "                [\n",
    "                    (\n",
    "                        \"categorical\",\n",
    "                        preprocessing.OneHotEncoder(sparse=False, handle_unknown=\"ignore\"),\n",
    "                        categorical_feature_indices,\n",
    "                    ),\n",
    "                    (\n",
    "                        \"continuous\",\n",
    "                        impute.SimpleImputer(strategy=\"median\"),\n",
    "                        numeric_feature_indices,\n",
    "                    ),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        (\"Classifier\", ensemble.RandomForestClassifier(n_estimators=10)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "run = openml.runs.run_model_on_task(pipe, task, avoid_duplicate_runs=False, dataset_format=\"array\")\n",
    "myrun = run.publish()\n",
    "print(f\"Uploaded to {myrun.openml_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running flows on tasks offline for later upload\n",
    "For those scenarios where there is no access to internet, it is possible to run\n",
    "a model on a task without uploading results or flows to the server immediately.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To perform the following line offline, it is required to have been called before\n",
    "# such that the task is cached on the local openml cache directory:\n",
    "task = openml.tasks.get_task(6)\n",
    "\n",
    "# The following lines can then be executed offline:\n",
    "run = openml.runs.run_model_on_task(\n",
    "    pipe, task, avoid_duplicate_runs=False, upload_flow=False, dataset_format=\"array\",\n",
    ")\n",
    "\n",
    "# The run may be stored offline, and the flow will be stored along with it:\n",
    "run.to_filesystem(directory=\"myrun\")\n",
    "\n",
    "# They may be loaded and uploaded at a later time\n",
    "run = openml.runs.OpenMLRun.from_filesystem(directory=\"myrun\")\n",
    "run.publish()\n",
    "\n",
    "# Publishing the run will automatically upload the related flow if\n",
    "# it does not yet exist on the server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, one can also directly run flows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a task\n",
    "task = openml.tasks.get_task(403)\n",
    "\n",
    "# Build any classifier or pipeline\n",
    "clf = tree.ExtraTreeClassifier()\n",
    "\n",
    "# Obtain the scikit-learn extension interface to convert the classifier\n",
    "# into a flow object.\n",
    "extension = openml.extensions.get_extension_by_model(clf)\n",
    "flow = extension.model_to_flow(clf)\n",
    "\n",
    "run = openml.runs.run_flow_on_task(flow, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Try to build the best possible models on several OpenML tasks,\n",
    "compare your results with the rest of the class and learn from\n",
    "them. Some tasks you could try (or browse openml.org):\n",
    "\n",
    "* EEG eye state: data_id:`1471 <https://www.openml.org/d/1471>`_,\n",
    "  task_id:`14951 <https://www.openml.org/t/14951>`_\n",
    "* Volcanoes on Venus: data_id:`1527 <https://www.openml.org/d/1527>`_,\n",
    "  task_id:`10103 <https://www.openml.org/t/10103>`_\n",
    "* Walking activity: data_id:`1509 <https://www.openml.org/d/1509>`_,\n",
    "  task_id:`9945 <https://www.openml.org/t/9945>`_, 150k instances.\n",
    "* Covertype (Satellite): data_id:`150 <https://www.openml.org/d/150>`_,\n",
    "  task_id:`218 <https://www.openml.org/t/218>`_, 500k instances.\n",
    "* Higgs (Physics): data_id:`23512 <https://www.openml.org/d/23512>`_,\n",
    "  task_id:`52950 <https://www.openml.org/t/52950>`_, 100k instances, missing values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easy benchmarking:\n",
    "for task_id in [115]:  # Add further tasks. Disclaimer: they might take some time\n",
    "    task = openml.tasks.get_task(task_id)\n",
    "    data = openml.datasets.get_dataset(task.dataset_id)\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "    run = openml.runs.run_model_on_task(clf, task, avoid_duplicate_runs=False)\n",
    "    myrun = run.publish()\n",
    "    print(f\"kNN on {data.name}: {myrun.openml_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openml.config.stop_using_configuration_for_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
